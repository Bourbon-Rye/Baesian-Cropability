{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "* It appears that parents of siblings are simple averages of the siblings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "datapath = Path(\"../datasets/prices\")\n",
    "writepath = Path(\"../datasets/prices-preclean\")\n",
    "\n",
    "def fix_month_year_ordering(df):\n",
    "    cols = df.columns.tolist()\n",
    "    date_month_cols = sorted([dt.datetime.strptime(x, \"%Y %b\") for x in cols[2:]])\n",
    "    date_month_cols = [dt.date.strftime(x, \"%Y %b\") for x in date_month_cols]\n",
    "    cols[2:] = date_month_cols\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "files = list(datapath.glob(\"*.csv\"))\n",
    "file = files[0]\n",
    "df = pd.read_csv(file, index_col=0)\n",
    "df.drop(list(df.filter(regex=\"Ave|Annual|2024\")), axis=1, inplace=True)  # Remove Ave, Annual, and 2024 Columns\n",
    "df = fix_month_year_ordering(df)\n",
    "print(df.isna().any(axis=1).sum())\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset filtered to 2018 has 6018 rows with NA values\n",
      "Dataset filtered to 2019 has 6018 rows with NA values\n",
      "Dataset filtered to 2020 has 6018 rows with NA values\n",
      "Dataset filtered to 2021 has 6018 rows with NA values\n",
      "Dataset filtered to 2022 has 6018 rows with NA values\n",
      "Dataset filtered to 2023 has 6018 rows with NA values\n",
      "Dataset filtered to 2024 has 6018 rows with NA values\n"
     ]
    }
   ],
   "source": [
    "# We noticed that there are a lot of \"<month> Annual\" values that are NA \n",
    "# We explore this\n",
    "for year in range(2018, 2025):\n",
    "    # print(df.filter(regex=f\"{year} Annual\"))\n",
    "    year_na = df.filter(regex=f\"{year} Annual\").isnull().any(axis=1).sum()\n",
    "    print(f\"Dataset filtered to {year} has {year_na} rows with NA values\")\n",
    "# df = df[df.columns.drop(list(df.filter(regex='Annual')))]\n",
    "\n",
    "# null_count = df.isna().any(axis=1).sum()\n",
    "# print('Number of rows with null values:', null_count)\n",
    "# # df.dropna(axis=0, inplace=True)\n",
    "# output_df = df[(df.drop([\"Geolocation\", \"Commodity\"], axis=1) != float(0)).any(axis=1)]\n",
    "# output_df.to_csv(\"datasets/clean/dummy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "df_grouped = df.groupby(\"Commodity Description\")\n",
    "geolocs = df_grouped.get_group(\"0 - ALL ITEMS\").Geolocation\n",
    "geolocs = list(geolocs)\n",
    "geolocs_rels = {}\n",
    "natl = \"PHILIPPINES\"\n",
    "region = None\n",
    "while len(geolocs) != 0:\n",
    "    loc = str(geolocs.pop(0))\n",
    "    if (loc == natl):\n",
    "        # Natl case\n",
    "        geolocs_rels.update({natl:{}})\n",
    "    elif (loc.startswith(\"....\")):\n",
    "        # Province or HUC case (discard if HUC)\n",
    "        if \"City\" in loc:\n",
    "            continue\n",
    "        province = loc.strip(\".\")\n",
    "        geolocs_rels[natl][region].append(province)\n",
    "    elif (loc.startswith(\"..\")):\n",
    "        # Region case\n",
    "        region = loc.strip(\".\")\n",
    "        geolocs_rels[natl].update({region:[]})\n",
    "        \n",
    "with open('region_provinces.json', 'w') as fp:\n",
    "    json.dump(geolocs_rels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\datasets\\New\\2M4ACP09 (1).csv\n",
      "..\\datasets\\New\\2M4ACP09 (2).csv\n",
      "..\\datasets\\New\\2M4ACP09 (3).csv\n",
      "..\\datasets\\New\\2M4ACP09 (4).csv\n",
      "..\\datasets\\New\\2M4ACP09 (5).csv\n",
      "..\\datasets\\New\\2M4ACP09 (6).csv\n",
      "..\\datasets\\New\\2M4ACP09 (7).csv\n",
      "..\\datasets\\New\\2M4ACP09 (8).csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "datapath = Path(\"../datasets/New\")\n",
    "for file in datapath.iterdir():\n",
    "    print(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baesians",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
